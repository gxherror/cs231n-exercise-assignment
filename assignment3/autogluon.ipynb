{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import autogluon.core as ag\n",
    "from autogluon.vision import ImageDataset,ImagePredictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 820/820 [00:00<00:00, 1092.02KB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>PetID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petfinder_data/train_images/015da9e87-1.jpg</td>\n",
       "      <td>015da9e87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petfinder_data/train_images/022606901-1.jpg</td>\n",
       "      <td>022606901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petfinder_data/train_images/02f89bdcb-1.jpg</td>\n",
       "      <td>02f89bdcb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petfinder_data/train_images/03f217352-1.jpg</td>\n",
       "      <td>03f217352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petfinder_data/train_images/040a9a6f9-1.jpg</td>\n",
       "      <td>040a9a6f9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         image      PetID  label\n",
       "0  petfinder_data/train_images/015da9e87-1.jpg  015da9e87      0\n",
       "1  petfinder_data/train_images/022606901-1.jpg  022606901      0\n",
       "2  petfinder_data/train_images/02f89bdcb-1.jpg  02f89bdcb      0\n",
       "3  petfinder_data/train_images/03f217352-1.jpg  03f217352      0\n",
       "4  petfinder_data/train_images/040a9a6f9-1.jpg  040a9a6f9      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = ag.utils.download('https://autogluon.s3-us-west-2.amazonaws.com/datasets/petfinder_example.csv')\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()\n",
    "#We use a csv file from PetFinder competition as an example. \n",
    "# You may use any tabular data as long as you can create image\n",
    "# (absolute or relative paths to images) and label(category for each image) columns.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/xherror/.gluoncv/archive/shopee-iet.zip from https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40895/40895 [02:09<00:00, 316.76KB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├── test/\n",
      "└── train/\n",
      "train # 800 test # 80\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/xherror/.gluoncv/datasets/shopee-iet/dat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/xherror/.gluoncv/datasets/shopee-iet/dat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/xherror/.gluoncv/datasets/shopee-iet/dat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/xherror/.gluoncv/datasets/shopee-iet/dat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/xherror/.gluoncv/datasets/shopee-iet/dat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
       "1  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
       "2  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
       "3  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
       "4  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, _, test_data = ImageDataset.from_folders('https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip', train='train', test='test')\n",
    "print('train #', len(train_data), 'test #', len(test_data))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├── test/\n",
      "└── train/\n",
      "                                                 image  label\n",
      "0    /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
      "1    /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
      "2    /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
      "3    /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
      "4    /home/xherror/.gluoncv/datasets/shopee-iet/dat...      0\n",
      "..                                                 ...    ...\n",
      "795  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      3\n",
      "796  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      3\n",
      "797  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      3\n",
      "798  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      3\n",
      "799  /home/xherror/.gluoncv/datasets/shopee-iet/dat...      3\n",
      "\n",
      "[800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, _, test_dataset = ImageDataset.from_folders('https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip')\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ImagePredictor sets accuracy as default eval_metric for classification problems.\n",
      "`time_limit=auto` set to `time_limit=7200`.\n",
      "Reset labels to [0, 1, 2, 3]\n",
      "Randomly split train_data into train[720]/validation[80] splits.\n",
      "The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "Starting fit without HPO\n",
      "modified configs(<old> != <new>): {\n",
      "root.train.early_stop_patience -1 != 10\n",
      "root.train.batch_size 32 != 16\n",
      "root.train.early_stop_baseline 0.0 != -inf\n",
      "root.train.epochs    200 != 2\n",
      "root.train.early_stop_max_value 1.0 != inf\n",
      "root.misc.num_workers 4 != 8\n",
      "root.misc.seed       42 != 105\n",
      "root.img_cls.model   resnet101 != resnet50\n",
      "}\n",
      "Saved config to /home/xherror/Repo/cs231n-exercise-assignment/cc61d202/.trial_0/config.yaml\n",
      "Model resnet50 created, param count:                                         23516228\n",
      "AMP not enabled. Training in float32.\n",
      "Disable EMA as it is not supported for now.\n",
      "Start training from [Epoch 0]\n",
      "Finished, total runtime is 1.38 s\n",
      "{ 'best_config': { 'batch_size': 16,\n",
      "                   'dist_ip_addrs': None,\n",
      "                   'early_stop_baseline': -inf,\n",
      "                   'early_stop_max_value': inf,\n",
      "                   'early_stop_patience': 10,\n",
      "                   'epochs': 2,\n",
      "                   'final_fit': False,\n",
      "                   'gpus': [0],\n",
      "                   'lr': 0.01,\n",
      "                   'model': 'resnet50',\n",
      "                   'ngpus_per_trial': 8,\n",
      "                   'nthreads_per_trial': 128,\n",
      "                   'num_workers': 8,\n",
      "                   'searcher': 'random',\n",
      "                   'seed': 105,\n",
      "                   'time_limits': 7200},\n",
      "  'total_time': 1.1501035690307617,\n",
      "  'train_acc': -1,\n",
      "  'valid_acc': -1}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error happened during fit: { 'args': \"{'img_cls': {'model': 'resnet50', 'pretrained': True, \"\n          \"'global_pool_type': None}, 'data': {'img_size': None, 'input_size': \"\n          \"None, 'crop_pct': 0.99, 'mean': None, 'std': None, 'interpolation': \"\n          \"'', 'validation_batch_size_multiplier': 1}, 'optimizer': {'opt': \"\n          \"'sgd', 'opt_eps': None, 'opt_betas': None, 'momentum': 0.9, \"\n          \"'weight_decay': 0.0001, 'clip_grad': None, 'clip_mode': 'norm'}, \"\n          \"'train': {'batch_size': 16, 'sched': 'step', 'lr': 0.01, \"\n          \"'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, \"\n          \"'lr_cycle_mul': 1.0, 'lr_cycle_limit': 1, 'transfer_lr_mult': 0.01, \"\n          \"'output_lr_mult': 0.1, 'warmup_lr': 0.0001, 'min_lr': 1e-05, \"\n          \"'epochs': 2, 'start_epoch': 0, 'decay_epochs': 30, 'warmup_epochs': \"\n          \"3, 'cooldown_epochs': 10, 'patience_epochs': 10, 'decay_rate': 0.1, \"\n          \"'bn_momentum': None, 'bn_eps': None, 'sync_bn': False, \"\n          \"'early_stop_patience': 10, 'early_stop_min_delta': 0.001, \"\n          \"'early_stop_baseline': -inf, 'early_stop_max_value': inf}, \"\n          \"'augmentation': {'no_aug': False, 'scale': (0.08, 1.0), 'ratio': \"\n          \"(0.75, 1.3333333333333333), 'hflip': 0.5, 'vflip': 0.0, \"\n          \"'color_jitter': 0.4, 'auto_augment': None, 'mixup': 0.0, 'cutmix': \"\n          \"0.0, 'cutmix_minmax': None, 'mixup_prob': 1.0, 'mixup_switch_prob': \"\n          \"0.5, 'mixup_mode': 'batch', 'mixup_off_epoch': 0, 'smoothing': 0.1, \"\n          \"'train_interpolation': 'random', 'drop': 0.0, 'drop_path': None, \"\n          \"'drop_block': None}, 'model_ema': {'model_ema': True, \"\n          \"'model_ema_force_cpu': False, 'model_ema_decay': 0.9998}, 'misc': \"\n          \"{'seed': 105, 'log_interval': 50, 'num_workers': 8, 'save_images': \"\n          \"False, 'amp': False, 'apex_amp': False, 'native_amp': False, \"\n          \"'pin_mem': False, 'prefetcher': False, 'eval_metric': 'top1', \"\n          \"'tta': 0, 'use_multi_epochs_loader': False, 'torchscript': False}, \"\n          \"'gpus': [0]}\",\n  'time': 1.1501035690307617,\n  'traceback': 'Traceback (most recent call last):\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/autogluon/vision/_gluoncv/image_classification.py\", '\n               'line 191, in _train_image_classification\\n'\n               '    result = estimator.fit(train_data=train_data, '\n               'val_data=val_data, time_limit=wall_clock_tick-tic)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/base_estimator.py\", '\n               'line 175, in fit\\n'\n               '    ret = self._fit(train_data, val_data, '\n               'time_limit=time_limit) if not resume else \\\\\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 123, in _fit\\n'\n               '    return self._resume_fit(train_data, val_data, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 201, in _resume_fit\\n'\n               '    return self._train_loop(train_loader, val_loader, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 239, in _train_loop\\n'\n               '    train_metrics = self.train_one_epoch(\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 337, in train_one_epoch\\n'\n               '    output = net(input)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\", '\n               'line 166, in forward\\n'\n               '    return self.module(*inputs[0], **kwargs[0])\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/timm/models/resnet.py\", '\n               'line 685, in forward\\n'\n               '    x = self.forward_features(x)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/timm/models/resnet.py\", '\n               'line 678, in forward_features\\n'\n               '    x = self.layer1(x)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\", '\n               'line 141, in forward\\n'\n               '    input = module(input)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/timm/models/resnet.py\", '\n               'line 417, in forward\\n'\n               '    x = self.conv3(x)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", '\n               'line 446, in forward\\n'\n               '    return self._conv_forward(input, self.weight, self.bias)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", '\n               'line 442, in _conv_forward\\n'\n               '    return F.conv2d(input, weight, bias, self.stride,\\n'\n               'RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB '\n               '(GPU 0; 1.96 GiB total capacity; 637.39 MiB already allocated; '\n               '47.94 MiB free; 698.00 MiB reserved in total by PyTorch) If '\n               'reserved memory is >> allocated memory try setting '\n               'max_split_size_mb to avoid fragmentation.  See documentation '\n               'for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n',\n  'train_acc': -1,\n  'valid_acc': -1}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_130648/2107466521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# since the original dataset does not provide validation split, the `fit` function splits it randomly with 90/10 ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# you can trust the default config, we reduce the # epoch to save some build time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/autogluon/vision/configs/presets_configs.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_presets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/autogluon/vision/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;31m# TODO: MXNetErrorCatcher was removed because it didn't return traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;31m#  Re-add once it returns full traceback regardless of which exception was caught\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mholdout_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/autogluon/vision/_gluoncv/image_classification.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, val_data, train_size, random_state, time_limit)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'traceback'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'timeout'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Unable to fit a usable model given `time_limit={time_limit}`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Unexpected error happened during fit: {pprint.pformat(results, indent=2)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_checkpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error happened during fit: { 'args': \"{'img_cls': {'model': 'resnet50', 'pretrained': True, \"\n          \"'global_pool_type': None}, 'data': {'img_size': None, 'input_size': \"\n          \"None, 'crop_pct': 0.99, 'mean': None, 'std': None, 'interpolation': \"\n          \"'', 'validation_batch_size_multiplier': 1}, 'optimizer': {'opt': \"\n          \"'sgd', 'opt_eps': None, 'opt_betas': None, 'momentum': 0.9, \"\n          \"'weight_decay': 0.0001, 'clip_grad': None, 'clip_mode': 'norm'}, \"\n          \"'train': {'batch_size': 16, 'sched': 'step', 'lr': 0.01, \"\n          \"'lr_noise': None, 'lr_noise_pct': 0.67, 'lr_noise_std': 1.0, \"\n          \"'lr_cycle_mul': 1.0, 'lr_cycle_limit': 1, 'transfer_lr_mult': 0.01, \"\n          \"'output_lr_mult': 0.1, 'warmup_lr': 0.0001, 'min_lr': 1e-05, \"\n          \"'epochs': 2, 'start_epoch': 0, 'decay_epochs': 30, 'warmup_epochs': \"\n          \"3, 'cooldown_epochs': 10, 'patience_epochs': 10, 'decay_rate': 0.1, \"\n          \"'bn_momentum': None, 'bn_eps': None, 'sync_bn': False, \"\n          \"'early_stop_patience': 10, 'early_stop_min_delta': 0.001, \"\n          \"'early_stop_baseline': -inf, 'early_stop_max_value': inf}, \"\n          \"'augmentation': {'no_aug': False, 'scale': (0.08, 1.0), 'ratio': \"\n          \"(0.75, 1.3333333333333333), 'hflip': 0.5, 'vflip': 0.0, \"\n          \"'color_jitter': 0.4, 'auto_augment': None, 'mixup': 0.0, 'cutmix': \"\n          \"0.0, 'cutmix_minmax': None, 'mixup_prob': 1.0, 'mixup_switch_prob': \"\n          \"0.5, 'mixup_mode': 'batch', 'mixup_off_epoch': 0, 'smoothing': 0.1, \"\n          \"'train_interpolation': 'random', 'drop': 0.0, 'drop_path': None, \"\n          \"'drop_block': None}, 'model_ema': {'model_ema': True, \"\n          \"'model_ema_force_cpu': False, 'model_ema_decay': 0.9998}, 'misc': \"\n          \"{'seed': 105, 'log_interval': 50, 'num_workers': 8, 'save_images': \"\n          \"False, 'amp': False, 'apex_amp': False, 'native_amp': False, \"\n          \"'pin_mem': False, 'prefetcher': False, 'eval_metric': 'top1', \"\n          \"'tta': 0, 'use_multi_epochs_loader': False, 'torchscript': False}, \"\n          \"'gpus': [0]}\",\n  'time': 1.1501035690307617,\n  'traceback': 'Traceback (most recent call last):\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/autogluon/vision/_gluoncv/image_classification.py\", '\n               'line 191, in _train_image_classification\\n'\n               '    result = estimator.fit(train_data=train_data, '\n               'val_data=val_data, time_limit=wall_clock_tick-tic)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/base_estimator.py\", '\n               'line 175, in fit\\n'\n               '    ret = self._fit(train_data, val_data, '\n               'time_limit=time_limit) if not resume else \\\\\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 123, in _fit\\n'\n               '    return self._resume_fit(train_data, val_data, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 201, in _resume_fit\\n'\n               '    return self._train_loop(train_loader, val_loader, '\n               'time_limit=time_limit)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 239, in _train_loop\\n'\n               '    train_metrics = self.train_one_epoch(\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/gluoncv/auto/estimators/torch_image_classification/torch_image_classification.py\", '\n               'line 337, in train_one_epoch\\n'\n               '    output = net(input)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\", '\n               'line 166, in forward\\n'\n               '    return self.module(*inputs[0], **kwargs[0])\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/timm/models/resnet.py\", '\n               'line 685, in forward\\n'\n               '    x = self.forward_features(x)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/timm/models/resnet.py\", '\n               'line 678, in forward_features\\n'\n               '    x = self.layer1(x)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\", '\n               'line 141, in forward\\n'\n               '    input = module(input)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/timm/models/resnet.py\", '\n               'line 417, in forward\\n'\n               '    x = self.conv3(x)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", '\n               'line 1102, in _call_impl\\n'\n               '    return forward_call(*input, **kwargs)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", '\n               'line 446, in forward\\n'\n               '    return self._conv_forward(input, self.weight, self.bias)\\n'\n               '  File '\n               '\"/home/xherror/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\", '\n               'line 442, in _conv_forward\\n'\n               '    return F.conv2d(input, weight, bias, self.stride,\\n'\n               'RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB '\n               '(GPU 0; 1.96 GiB total capacity; 637.39 MiB already allocated; '\n               '47.94 MiB free; 698.00 MiB reserved in total by PyTorch) If '\n               'reserved memory is >> allocated memory try setting '\n               'max_split_size_mb to avoid fragmentation.  See documentation '\n               'for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n',\n  'train_acc': -1,\n  'valid_acc': -1}"
     ]
    }
   ],
   "source": [
    "predictor = ImagePredictor()\n",
    "# since the original dataset does not provide validation split, the `fit` function splits it randomly with 90/10 ratio\n",
    "predictor.fit(train_dataset, hyperparameters={'epochs': 2})  # you can trust the default config, we reduce the # epoch to save some build time"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdb3ae18f5c2090b9c74a27d28999bb0a9367535041c05f7d7d541b8c3c742a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
